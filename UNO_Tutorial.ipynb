{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNO_Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5sLspEnB73-I",
        "YmX7VzmwsNl4"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashiq24/UNO/blob/main/UNO_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# U-shaped Neural operator\n",
        "This tutorial gives a step by step break down on how to use the U shaped Neural Operators (UNO), which is introduced in the paper with the same title U-NO: [U-shaped Neural Operators](https://arxiv.org/pdf/2204.11127.pdf). This \n",
        "\n",
        "First we need to download few files from the github repository of UNO. The file **integral_operators.py** contrains non-linear integral operators, the building block of U-NO."
      ],
      "metadata": {
        "id": "6QbHWRs1Pa90"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DPjNx0AvASYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fdc7230-6ed6-4fb2-e857-0b96c51d4b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-27 05:02:14--  https://raw.githubusercontent.com/ashiq24/UNO/main/Adam.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6562 (6.4K) [text/plain]\n",
            "Saving to: ‘Adam.py’\n",
            "\n",
            "Adam.py             100%[===================>]   6.41K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-27 05:02:14 (62.1 MB/s) - ‘Adam.py’ saved [6562/6562]\n",
            "\n",
            "--2022-05-27 05:02:14--  https://raw.githubusercontent.com/ashiq24/UNO/main/utilities3.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2957 (2.9K) [text/plain]\n",
            "Saving to: ‘utilities3.py’\n",
            "\n",
            "utilities3.py       100%[===================>]   2.89K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-27 05:02:14 (26.2 MB/s) - ‘utilities3.py’ saved [2957/2957]\n",
            "\n",
            "--2022-05-27 05:02:15--  https://raw.githubusercontent.com/ashiq24/UNO/main/integral_operators.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15146 (15K) [text/plain]\n",
            "Saving to: ‘integral_operators.py’\n",
            "\n",
            "integral_operators. 100%[===================>]  14.79K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-05-27 05:02:15 (28.1 MB/s) - ‘integral_operators.py’ saved [15146/15146]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/ashiq24/UNO/main/Adam.py\n",
        "!wget https://raw.githubusercontent.com/ashiq24/UNO/main/utilities3.py\n",
        "!wget https://raw.githubusercontent.com/ashiq24/UNO/main/integral_operators.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import operator\n",
        "from functools import reduce\n",
        "from functools import partial\n",
        "from timeit import default_timer\n",
        "from utilities3 import *\n",
        "from Adam import Adam\n",
        "from torchsummary import summary\n",
        "import gc\n",
        "import math\n",
        "from integral_operators import * "
      ],
      "metadata": {
        "id": "JvFZ5sJEBVef"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example\n",
        "Let's we have a function $f(x,y) = [x^2+y, x+y^2]$ where $(x,y) \\in (0,1)^2$. So, it's domain is $2D$ and co-domain dimension is also 2. \n",
        "\n",
        "We will apply non-linear operator $G$ (linear integral operators\n",
        "followed by point-wise non-linearity) on the function $f$ such that $g = G(f)$.\n",
        "\n",
        "Where, $g$ is defined on domain $(0.0,0.5)^2$ with 4 dimentional co-domain i.e.,\n",
        "\n",
        " $g: (0.0.5)^2 \\to R^4$\n",
        "\n",
        "For this example, we will use a non-linear operator perfroming $2D$ integral operation. It is implemented as the class **OperatorBlock_2D** in **integral_operators.py** module. It uses **SpectralConv2d_Uno** for kernel integration and **pointwise_op_2D** for point-wise operator. Details can be found in the paper.\n",
        "\n",
        "##Discretization\n",
        "To work with the input function $f$ anlytically, we need to discretize its' domian $(0,1)^2$. We will discretize the domain with a grid fo size $100 \\times 100$ (sampling rate 0.01).\n",
        "\n",
        "Following the same sampling rate, the output function with domain $(0.0,0.5)^2$ will have a grid size of $50 \\times 50$\n",
        "\n",
        "##Domain Contraction and Expansion\n",
        "\n",
        "Note that by using operator $G$ we are contracting the domian of input function $f$ by a factor of $0.5$  ($(0,1)^2$ to $(0.0,0.5)^2$). This contraction factor can also be expressed a the ratio of grid size along each dimension of the domain the input and functions (100 to 50).\n",
        "\n",
        "\n",
        "\n",
        "Now let's get to the code."
      ],
      "metadata": {
        "id": "YZgBXqiNXxUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the input function"
      ],
      "metadata": {
        "id": "z0AtVEeFfGqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func(x, y):\n",
        "    return [x**2+y,x+y**2]\n",
        "\n",
        "xaxis = np.linspace(0, 1, 100)\n",
        "yaxis = np.linspace(0, 1, 100)\n",
        "function_f = func(xaxis[:,None], yaxis[None,:])"
      ],
      "metadata": {
        "id": "Zl6Ej18ACuV9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f  = torch.tensor(function_f)"
      ],
      "metadata": {
        "id": "SB5wupgkgTuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce4eb398-6ca9-4159-b850-14b041245498"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f.shape # note that co-domain dimension is at the begining."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WMsYeu5gVRX",
        "outputId": "cce8db9e-d6b6-48a8-f07d-5d6ee931ac3b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 100, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will initialize our operator $G$. We need to pass several parameters to the class OperatorBlock_2d.\n",
        "\n",
        "###**OperatorBlock_2d(in_codim, out_codim,dim1, dim2,modes1,modes2, Normalize = False,Non_Lin = True)**\n",
        "        \n",
        "1.   in_codim = co-domain dimension of input function (for $f$ this is 2)\n",
        "2.   out_codim = co-domain dimension of output function (for $g$ this is 4)\n",
        "3.   dim1 = Default output grid size along $x$ axis of the output function $g$. Which is 50 in out case.\n",
        "4.   dim2 = Default output grid size along $y$  axis of the output function $g$. This is also 50.\n",
        "5. modes1 and modes2 = Number of fourier model the operator will use to perform the kernel integration (we set both of them as 10). *As we are using FFT to approximate the transfrom, we must satisfy that modes1 < min(dim1/2, input_dim1/2). input_dim1 is grid size along $x$ axis of the input function. The same condition is also applied for other modes.*\n",
        "6. Normalize = If set to True performs InstanceNorm2d, by default it is set to False\n",
        "7. Non_Lin = If True, applies point wise nonlinearity (Gelu). We can set it to False if we need liniear operator.\n",
        "\n",
        "\n",
        "#### Note:\n",
        "Neural operator is discretization invarient. That means, the same operator can handle the function $f$ with discretization of grid size (100x100) and also with iscretization of grid size (1000x1000). The discretization of output function $g$ will also be changed in the same way.\n",
        "\n",
        "But often time we train the model with fixed discretization. The option for default output grid size is kept considering the ease in coding duirng traing the neural operators.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4oR7X_ORi-H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# intizalizing the oprator\n",
        "G = OperatorBlock_2D(2,4,50,50,10,10)\n",
        "f = f.reshape(1,2,100,100) #adding a batch dimension\n",
        "g = G(f.float())\n",
        "print(g.shape)"
      ],
      "metadata": {
        "id": "ZPOeAFHggc3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35a48e7-b07e-4b9c-d429-eb7805fd30e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 50, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The forward function of the class **OperatorBlock_2D** also has two other parameter fixing the grid size of the output function.\n",
        "\n",
        "In other words, we can also calculate $g$ in the following way."
      ],
      "metadata": {
        "id": "lG9AKV_vq8WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = G(f.float(), dim1 = 50, dim2 = 50)\n",
        "print(g.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGz3mk-1qwTd",
        "outputId": "b44527a7-69c0-4a1d-96db-43a69d4a4101"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 50, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Breaking down the Operator Block.\n",
        "\n",
        "**OperatorBlock_2D** uses **SpectralConv2d_Uno** and **pointwise_op_2D** for performing the non-linear integral operation.\n",
        "\n",
        "The operator action in the pervious cell can be broken down as the following\n",
        "\n"
      ],
      "metadata": {
        "id": "5sLspEnB73-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "I = SpectralConv2d_Uno(2,4,50,50,10,10) # Initializing the kernel integral operator\n",
        "p = pointwise_op_2D(2,4,50,50) #Initializing the pointwise operator\n",
        "\n",
        "g = F.gelu(I(f.float())+ p(f.float()))\n",
        "print(g.shape)"
      ],
      "metadata": {
        "id": "mqxk0azOoo8y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3126d0d9-ccac-4d6d-efd6-03dffafb534e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 50, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling finer discretization\n",
        "Now, assume that we recive the input function with finer discreetization over the input domain (grid size 1000x 1000).\n",
        "\n",
        "Maintaining the contraction ratio, the grid size of the output function $g$ will be $500 \\times 500$. Now, we can use the same operator $G$ to get the output function $g$ with finer discretization."
      ],
      "metadata": {
        "id": "YmX7VzmwsNl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#input function with finer discretization.\n",
        "xaxis = np.linspace(0, 1, 1000)\n",
        "yaxis = np.linspace(0, 1, 1000)\n",
        "function_f_finer = func(xaxis[:,None], yaxis[None,:])\n",
        "f_finer  = torch.tensor(function_f_finer)\n",
        "print(f_finer.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SOrX3hxsNDf",
        "outputId": "0861d6e4-d38e-4211-c4b1-a5ee42782c7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1000, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " We can use the operator **G**, previously intitialized, to get the output function $g$. \n",
        "\n",
        "Note, as the discretiztion of **g** is not the same as the default grid size defined during the initializtion of **G**, we need specify it in the function call ***G()***."
      ],
      "metadata": {
        "id": "_bw4wGsfvzms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_finer = f_finer.reshape(1,2,1000,1000)\n",
        "g_finer = G(f_finer.float(), dim1 = 500, dim2 = 500)\n",
        "print(g_finer.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUQum7d0vwJ0",
        "outputId": "ea030f03-7ba0-435b-e286-a18a0bfa27ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 500, 500])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating and Training a U-NO\n",
        "\n",
        "There are three main components in U-NO\n",
        "\n",
        "1. Lifting operator P (Lift the input function to higher dimentional Co-domain)\n",
        "2. Stacked non-linear integral operator G\n",
        "3. Projection operator Q (Project the function to lower dimensional Co-domain) \n",
        "\n",
        "####Things to note:\n",
        "1. The co-domain dimension should be kept at the end. So, the function $f$ used above as an example will have the shape (100,100,2) after discretization with grid size 100x100. \n",
        "2. Following the paper we will also concatenate position (x & Y) along the co-domain dimesion.\n",
        "3. If the function is non-periodic, we extend the domain by zero padding.\n",
        "\n",
        "In the following we will create a UNO 2D model."
      ],
      "metadata": {
        "id": "v1VB9jbPKqKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNO_demo(nn.Module):\n",
        "    def __init__(self, in_width, width,pad = 8):\n",
        "        super(UNO_demo, self).__init__()\n",
        "   \n",
        "        self.in_width = in_width # input function co-domain dimention after concatenating (x,y)\n",
        "        self.width = width # lifting dimension\n",
        "        \n",
        "        self.padding = pad  # passing amount\n",
        "\n",
        "        self.fc = nn.Linear(self.in_width, self.width//2)\n",
        "\n",
        "        self.fc0 = nn.Linear(self.width//2, self.width) \n",
        "\n",
        "        self.G0 = OperatorBlock_2D(self.width, 2*self.width,32, 32, 14, 14)\n",
        "\n",
        "        self.G1 = OperatorBlock_2D(2*self.width, 4*self.width, 16, 16, 6,6)\n",
        "\n",
        "        self.G2 = OperatorBlock_2D(4*self.width, 8*self.width, 8, 8,3,3)\n",
        "        \n",
        "        self.G3 = OperatorBlock_2D(8*self.width, 16*self.width, 4, 4,2,2)\n",
        "        \n",
        "        self.G4 = OperatorBlock_2D(16*self.width, 16*self.width, 4, 4,2,2)\n",
        "        \n",
        "        self.G5 = OperatorBlock_2D(16*self.width, 16*self.width, 4, 4,2,2)\n",
        "        \n",
        "        self.G6 = OperatorBlock_2D(16*self.width, 16*self.width, 4, 4,2,2)\n",
        "        \n",
        "        self.G7 = OperatorBlock_2D(16*self.width, 16*self.width, 4, 4,2,2)\n",
        "        \n",
        "        self.G8 = OperatorBlock_2D(16*self.width, 16*self.width, 4, 4,2,2)\n",
        "        \n",
        "        self.G9 = OperatorBlock_2D(16*self.width, 8*self.width, 8, 8,2,2)\n",
        "        \n",
        "        self.G10 = OperatorBlock_2D(16*self.width, 4*self.width, 16, 16,3,3)\n",
        "\n",
        "        self.G11 = OperatorBlock_2D(8*self.width, 2*self.width, 32, 32,6,6)\n",
        "\n",
        "        self.G12 = OperatorBlock_2D(4*self.width, self.width, 64, 64,14,14) # will be reshaped\n",
        "\n",
        "        self.fc1 = nn.Linear(1*self.width, 2*self.width)\n",
        "        self.fc2 = nn.Linear(2*self.width, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        grid = self.get_grid(x.shape, x.device)\n",
        "        x = torch.cat((x, grid), dim=-1) # concatenating position (x,y) along the co-domain\n",
        "\n",
        "        x_fc = self.fc(x)\n",
        "        x_fc = F.gelu(x_fc)\n",
        "\n",
        "        x_fc0 = self.fc0(x_fc)\n",
        "        x_fc0 = F.gelu(x_fc0)\n",
        "        \n",
        "        x_fc0 = x_fc0.permute(0, 3, 1, 2)\n",
        "        x_fc0 = F.pad(x_fc0, [0,self.padding, 0,self.padding])\n",
        "        \n",
        "        D1,D2 = x_fc0.shape[-2],x_fc0.shape[-1]\n",
        "\n",
        "        x_c0 = self.G0(x_fc0,D1//2,D2//2)\n",
        "\n",
        "        x_c1 = self.G1(x_c0,D1//4,D2//4)\n",
        "\n",
        "        x_c2 = self.G2(x_c1,D1//8,D2//8)\n",
        "  \n",
        "        x_c3 = self.G3(x_c2,D1//16,D2//16)\n",
        "        \n",
        "        x_c4 = self.G4(x_c3,D1//16,D2//16)\n",
        " \n",
        "        x_c5 = self.G5(x_c4,D1//16,D2//16)\n",
        "\n",
        "        x_c6 = self.G6(x_c5,D1//16,D2//16)\n",
        "        \n",
        "        x_c7 = self.G7(x_c6,D1//16,D2//16)\n",
        "        \n",
        "        x_c8 = self.G8(x_c7,D1//16,D2//16)\n",
        " \n",
        "        x_c9 = self.G9(x_c8,D1//8,D2//8)\n",
        "        x_c9 = torch.cat([x_c9, x_c2], dim=1) \n",
        "        \n",
        "        x_c10 = self.G10(x_c9 ,D1//4,D2//4)\n",
        "        x_c10 = torch.cat([x_c10, x_c1], dim=1)\n",
        "\n",
        "        x_c11 = self.G11(x_c10 ,D1//2,D2//2)\n",
        "        x_c11 = torch.cat([x_c11, x_c0], dim=1)\n",
        "\n",
        "        x_c12 = self.G12(x_c11,D1,D2)\n",
        "        if self.padding!=0:\n",
        "            x_c12 = x_c12[..., :-self.padding, :-self.padding]\n",
        "\n",
        "\n",
        "        x_c12 = x_c12.permute(0, 2, 3, 1)\n",
        "\n",
        "        x_fc1 = self.fc1(x_c12)\n",
        "        x_fc1 = F.gelu(x_fc1)\n",
        "        x_out = self.fc2(x_fc1)\n",
        "        \n",
        "        return x_out\n",
        "    \n",
        "    def get_grid(self, shape, device):\n",
        "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
        "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
        "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
        "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
        "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
        "        return torch.cat((gridx, gridy), dim=-1).to(device)"
      ],
      "metadata": {
        "id": "CejApP4CKvca"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use image as our $2D$ function over the domain $[0,1]^2$. The input resolution is $64 \\times 64$ and the co-domain dimension is 3 (RGB images).\n",
        "\n",
        "As an example, we will perfrom image denoisng with out U-NO."
      ],
      "metadata": {
        "id": "yv0dovy13-dM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import EuroSAT\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "Bm7lAb8i6x8A"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = EuroSAT(\"\",download = True,transform = transforms.ToTensor())"
      ],
      "metadata": {
        "id": "IzJUXdxs5d3-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(x, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "tkL4rRlx63DE"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNO_demo(5,16) # in_width = 5 as we will concatenate (x,y) along with the channels of the images"
      ],
      "metadata": {
        "id": "5WNHQ6lm39wD"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(model.parameters(), lr=0.0001, weight_decay=0.001,amsgrad = False)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.8)\n",
        "myloss = LpLoss(size_average=False) #it calculates the error rate\n",
        "model.train()\n",
        "for ep in range(100): #training from 1000 epocs\n",
        "    train_l2 = 0\n",
        "    for x, y in train_loader:\n",
        "        batch_size = x.shape[0]\n",
        "        x = x.permute(0, 2,3,1) # taking co-domain dimension (or channel of images) to end\n",
        "        x_in = x + 0.1* torch.randn_like(x)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x_in).reshape(batch_size, 64, 64,3)\n",
        "        loss = myloss(out.reshape(batch_size,-1), x.reshape(batch_size,-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        train_l2 += loss.item()\n",
        "        del x,y,out,loss\n",
        "        gc.collect()\n",
        "    scheduler.step()\n",
        "    train_l2/= 1000\n",
        "    print(\"Episode \",ep,\" Traing Error \", train_l2)"
      ],
      "metadata": {
        "id": "OiS6ssJEyeiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JhCvP8Uj8R_o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}